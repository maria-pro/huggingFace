# 1.2.1. HF Hub

### HF Hub





{% hint style="info" %}
What we wil cover:

* Understand the Hugging Face structure
* Search and navigate the Models tab
* Search and navigate the Datasets
* Use Spaces and Hugging Face community/collaboration options
{% endhint %}



* Understand the basic usage of Hugging Face models.
* Run simple code examples to see the models in action.
* Get hands-on experience with different types of models.

Welcome! Let's have a look at Hugging Face hub and think about a small project  - as you know the coding and builidng your portfolio are the most important things for your career.

We looked briefly at the Hugging Face website. Now, let’s head to Hugging Face hub and a look at all the treasures that are hidden there! And there is a LOT - Hugging Face is one of the best ML platforms that has everything in one place - from data to models and tools to use them on the go.&#x20;

But let's start doing things!

Hugging Face hub is build around four components:

<mark style="background-color:purple;">1. Models</mark>

<mark style="background-color:purple;">2. Datasets</mark>

<mark style="background-color:purple;">3. Documentation - docs</mark>

<mark style="background-color:purple;">4. Spaces and community</mark>

\
Let's open the HF website - huggingface.co and explore all those components

![](https://lh7-us.googleusercontent.com/docsz/AD\_4nXesuATu53PmwlYUFtvemIXgpr5YmUrfBAwpOEmwmFQwcGIdxvIg1-PZM49Fcbtn37V8EqmqCr-83N5DGacBBswckLqQbMs5F4tgO0ty8U1r0I\_ZTVTuTQg5Bg0V3BDWe5oqs77huhy1QIktPR\_wMQAhc6Vi?key=pwjwodfWMnUxIFMintqadw)

#### Models

Let's start with models!&#x20;

The Hub has  a vast collection of pre-trained models, they have amazing subcollection for various NLP tasks such as text classification, named entity recognition, question answering, and more. Some of the most noteable models are&#x20;

* BERT
* GPT, GPT-2, GPT-3
* RoBERTa
* DistilBERT
* T5
* BART, and many others.

But there are models for many other tasks such as working with vision, audio and a multimodal models which is a combination of different modalities, such as text and visual in a particular context!&#x20;

**Finding models**: On the homepage, click on the “Models” tab and search for some models, such as BERT or GPT-3.

We can filter models by tasks such as&#x20;

* text classification
* translation
* summarization

or libraries you use, such as&#x20;

* Transformers (which we will talk about)
* PyTorch (which we will also use!)
* TensorFlow and more.&#x20;

You can get all the information about the model from its model card - its usage, performance metrics, and example code snippets.

I absolutely love code snippets - it feels like cheating as we can copy those snippets and start using this model in. your project straight away, not writing a single line of code yourself!

Have a look at [BERT](https://huggingface.co/google-bert/bert-base-uncased) from Google. It is a very popular model as you see on its downloads count: Downloads last month 55,914,070

As you see in the description, this model is based on a this [paper](https://arxiv.org/abs/1810.04805) and is published originally in this [Github repository](https://github.com/google-research/bert).

It also has model variations for different use cases (Model variations). It was trained on two datasets: wikipedia and book corpus, which are also available on Hugging Face.

The code snippet makes it really easy to try this model with the `transformer` library, so let's try it in the Google Colab

And let's try this code snippet:

```python
from transformers import pipeline
unmasker = pipeline('fill-mask', model='bert-base-uncased')
unmasker("Hello I'm a [MASK] model.")

```

and we can run our own

```python
from transformers import pipeline
unmasker = pipeline('fill-mask', model='bert-base-uncased')
unmasker("Dark chocolate is a [MASK] food.")

```

#### Datasets

Next, let's move to the Datasets section. Data is critical. No data no project.&#x20;

Hugging Face provides access to a multitude of datasets. Let's look at some.

**Finding Datasets**: Click on the “Datasets” tab. You can search for datasets based on tasks, their size, and other attributes.&#x20;

Similar to models, each dataset comes with a detailed card that includes:

* the dataset description
* features, and&#x20;
* usage examples.

For example, lets look at `rotten_tomatoes` dataset [here](https://huggingface.co/datasets/cornell-movie-review-data/rotten\_tomatoes)

We can see that this is a movie review dataset where reviews are labeled as positive or negative. We have 5,331 positive and 5,331 negative ones.

We can see the example of usage under `Use this dataset` tab and we can select the `datasets` library as this is exactly what we are going to use later. We just copy this code and use it in our Google Colab

```python
from datasets import load_dataset
ds = load_dataset("cornell-movie-review-data/rotten_tomatoes")
```

#### Documentation

Our next stop is Docs or documentation. I absolutely love the way Hugging Face organised this section as you can see some `Quick start` tutorials as well as in-depth documentation there.&#x20;

We will work closely with this section throughout this course. So it is a good idea to bookmark it!

#### Spaces and Community

It is one of the most exciting aspects of Hugging Face - its community and collaboration!

**Community Involvement**: The Hugging Face community is vibrant and active.&#x20;

You can find the under the `Community` link.

You can join the discussion forums, contribute to projects, and participate in events like sprints and hackathons. The community is a great place to learn, share knowledge, and collaborate with others passionate about AI.

and <mark style="color:purple;">finally!</mark>

**Spaces**: Spaces is a relatively new feature that allows users to create and share interactive demos. It allows to deploy models and datasets in an interactive format that can be accessed and used by others. You can create your own Space to showcase your models or explore Spaces created by others for inspiration.

For example, let's have a look at this space that showcases [Stable Diffusion 3 Medium](https://huggingface.co/stabilityai/stable-diffusion-3-medium) model

and this prompt

> hot chocolate in a cosy winter morning

Have a look at the great image it generates!&#x20;

<figure><img src="../../.gitbook/assets/stable diffusion.png" alt="" width="375"><figcaption></figcaption></figure>

That was a good look! We covered models, datasets, and community and had a play with spaces! In the next video we will look very closely on how we can make models to work for our project! &#x20;

<mark style="color:purple;">But before - in suggest that you spend some time on Hugging Face and look for models and datasets that are of interest to your personally.</mark>&#x20;

<mark style="color:green;">This is HOW I LEARNT myself and it worked perfectly for me!</mark>&#x20;

<mark style="color:purple;">Nothing works better than DOING things, so start exploring!</mark>

***

Here are some practical exercises to get you started:

\


1\. \*\*Experiment with Models\*\*: Choose a model from the Hugging Face Model Hub and integrate it into your project. Try different tasks like text generation, translation, or question answering.

\


2\. \*\*Explore Datasets\*\*: Load a dataset from the Datasets Hub and perform basic data exploration and manipulation. Experiment with filtering and transforming the dataset to suit your needs.

\


3\. \*\*Create a Space\*\*: Use Gradio or Streamlit to create a simple interactive demo of a model. Deploy it on Hugging Face Spaces and share it with the community.

\


4\. \*\*Read the Docs\*\*: Pick a guide or tutorial from the documentation and follow along. Implement the examples and try extending them with your own modifications.



Finally!

Hugging Face is a treasure trove of AI resources, and by exploring its models, datasets, documentation, and community features, you can significantly boost your machine learning projects. Dive in, experiment, and don't hesitate to reach out to the community for support. Happy exploring!

\
\
