---
description: This part is on `transformers` library
---

# Meet Transformers!

#### Module 1.4. Transformers

| What are transformers?                                                          |
| ------------------------------------------------------------------------------- |
| Why transformers? and what was before them                                      |
| Attention is all you need! where it all started                                 |
| What do we need to know about the attention mechanism                           |
| Key concepts behind transformers: attention heads, layers, positional encoding. |
| Attention heads                                                                 |
| Layers                                                                          |
| Positional encoding                                                             |
| Simplified explanation of self-attention and its advantages over RNNs and CNNs. |
| Architecture of a basic transformer model                                       |
| Encoders and decoders explained                                                 |
| How data flows through a transformer model                                      |
| Visual diagrams to illustrate model components                                  |
| Understanding pre-trained transformer models                                    |
| Examples of pre-trained models: BERT and GPT-2                                  |
| General applications of these models                                            |
| Step-by-step guide to loading a pre-trained model using Hugging Face            |
| Basic fine-tuning concepts                                                      |
| Why fine-tuning?                                                                |
| Basic steps to fine-tune a transformer model on a new dataset.                  |
| Overview of parameters that commonly need adjustments.                          |
| Simple demo                                                                     |
| Transformer models in practice                                                  |
| Conclusion                                                                      |





What are transformers?

Why transformers? and what was before them

Attention is all you need! where it all started
