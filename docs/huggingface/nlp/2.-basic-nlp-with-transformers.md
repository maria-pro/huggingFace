# 2. Basic NLP with transformers

| Using a transformer for inference                                                          |
| ------------------------------------------------------------------------------------------ |
| Tokenizers                                                                                 |
| Different types and how to choose                                                          |
| Encoding                                                                                   |
| Decoding                                                                                   |
| Multiple sequences                                                                         |
| Let's make it work                                                                         |
| Fine-tuning models                                                                         |
| Why fine-tuning                                                                            |
| Fine-Tuning                                                                                |
| Steps in fine-tuning                                                                       |
| Fine-tuning approaches                                                                     |
| Even more fine-tuning: gradient accumulation, learning rate scheduling, and warm-up steps  |
| Evaluation                                                                                 |
| Let's put this to work                                                                     |

| Comparing models and selecting the model to use  |
| ------------------------------------------------ |
| Planning the work and understanding the workflow |
